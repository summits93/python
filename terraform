Certainly! Below is a sample Terraform configuration to deploy a simple web application with a load balancer in Google Cloud Platform (GCP). This example assumes you have a simple web application deployed in a Google Compute Engine (GCE) instance.

```hcl
provider "google" {
  project = "your_project_id"
  region  = "us-central1"
}

# Create a Google Compute Engine instance
resource "google_compute_instance" "web_instance" {
  name         = "web-instance"
  machine_type = "n1-standard-1"
  zone         = "us-central1-a"

  boot_disk {
    initialize_params {
      image = "debian-cloud/debian-10"
    }
  }

  network_interface {
    network = "default"
    access_config {
      // Ephemeral IP
    }
  }

  metadata_startup_script = "apt-get update && apt-get install -y apache2 && systemctl enable apache2 && systemctl start apache2 && echo 'Hello, World!' | sudo tee /var/www/html/index.html"
}

# Create a Google Compute Engine firewall rule to allow traffic on port 80
resource "google_compute_firewall" "http_firewall" {
  name    = "allow-http"
  network = "default"

  allow {
    protocol = "tcp"
    ports    = ["80"]
  }

  source_ranges = ["0.0.0.0/0"]
}

# Create a Google Compute Engine instance group
resource "google_compute_instance_group" "web_instance_group" {
  name        = "web-instance-group"
  zone        = "us-central1-a"
  description = "Instance group for web instances"

  instances = [google_compute_instance.web_instance.self_link]
}

# Create a Google Compute Engine health check
resource "google_compute_http_health_check" "web_health_check" {
  name               = "web-health-check"
  request_path       = "/"
  check_interval_sec = 1
  timeout_sec        = 1
}

# Create a Google Compute Engine backend service
resource "google_compute_backend_service" "web_backend_service" {
  name                  = "web-backend-service"
  backend {
    group = google_compute_instance_group.web_instance_group.self_link
  }
  health_checks         = [google_compute_http_health_check.web_health_check.self_link]
  load_balancing_scheme = "EXTERNAL"
}

# Create a Google Compute Engine URL map
resource "google_compute_url_map" "web_url_map" {
  name            = "web-url-map"
  default_service = google_compute_backend_service.web_backend_service.self_link
}

# Create a Google Compute Engine target HTTP proxy
resource "google_compute_target_http_proxy" "web_target_http_proxy" {
  name    = "web-target-http-proxy"
  url_map = google_compute_url_map.web_url_map.self_link
}

# Create a Google Compute Engine global forwarding rule
resource "google_compute_global_forwarding_rule" "web_forwarding_rule" {
  name       = "web-forwarding-rule"
  target     = google_compute_target_http_proxy.web_target_http_proxy.self_link
  port_range = "80"
}
```

This Terraform configuration creates:

1. A Google Compute Engine instance with Apache installed and serving a simple "Hello, World!" web page.
2. A firewall rule to allow traffic on port 80.
3. An instance group containing the created instance.
4. A health check to monitor the health of the instance.
5. A backend service referencing the instance group and health check.
6. A URL map and target HTTP proxy to route incoming traffic to the backend service.
7. A global forwarding rule to forward incoming traffic on port 80 to the target HTTP proxy.

You can customize this configuration further based on your specific requirements, such as using a different machine type, customizing the startup script, or deploying multiple instances for high availability. Don't forget to replace `"your_project_id"` with your actual GCP project ID.